{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRsprawphIM3"
      },
      "source": [
        "# Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B81ESDhECfV9",
        "outputId": "2898dc74-15cd-400a-f3aa-dd38967e684b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai==0.28.0 in /usr/local/lib/python3.11/dist-packages (0.28.0)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.24)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (1.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.11/dist-packages (from openai==0.28.0) (2.32.3)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from openai==0.28.0) (3.11.15)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.55 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.56)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.39)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.4)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.55->langchain) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.55->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.55->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.55->langchain) (4.13.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28.0) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28.0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28.0) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28.0) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28.0) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28.0) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28.0) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28.0) (1.20.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.55->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai==0.28.0 langchain python-dotenv tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9t7Z4pPDBuW"
      },
      "source": [
        "Setup Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BELu12qQC1EP",
        "outputId": "616251c0-2484-4d23-e96a-6c87674af960"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: python-pptx in /usr/local/lib/python3.11/dist-packages (1.0.2)\n",
            "Requirement already satisfied: Pillow>=3.3.2 in /usr/local/lib/python3.11/dist-packages (from python-pptx) (11.2.1)\n",
            "Requirement already satisfied: XlsxWriter>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from python-pptx) (3.2.3)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-pptx) (5.4.0)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-pptx) (4.13.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install python-pptx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6UKotSRZLP-",
        "outputId": "bedf940d-f501-47b9-9982-2325601fb799"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.11/dist-packages (3.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install PyPDF2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVVLwy1LC98N"
      },
      "source": [
        "Text Extraction and Chunking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "igM9RaqpDA78"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import openai\n",
        "from pptx import Presentation\n",
        "from PyPDF2 import PdfReader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from dotenv import load_dotenv\n",
        "from tqdm import tqdm\n",
        "# Load API keys from .env\n",
        "load_dotenv()\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "# Setup Directories\n",
        "BASE_DIR = \"/CTSE\"\n",
        "TEXT_DIR = \"ctse_extracted_txt_files\"\n",
        "os.makedirs(TEXT_DIR, exist_ok=True)\n",
        "\n",
        "def extract_pdf_text(filepath):\n",
        "    try:\n",
        "        with open(filepath, 'rb') as f:\n",
        "            reader = PyPDF2.PdfReader(f)\n",
        "            text = \"\"\n",
        "            for page in reader.pages:\n",
        "                text += page.extract_text() + \"\\n\"\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting PDF {filepath}: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "# Function to extract text from PPTX\n",
        "def extract_pptx_text(filepath):\n",
        "    try:\n",
        "        prs = Presentation(filepath)\n",
        "        text = \"\"\n",
        "        for slide in prs.slides:\n",
        "            for shape in slide.shapes:\n",
        "                if hasattr(shape, \"text\"):\n",
        "                    text += shape.text + \"\\n\"\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting PPTX {filepath}: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "# Function to extract and chunk text\n",
        "def extract_and_chunk_text():\n",
        "    text_with_topics = []\n",
        "    for filepath in tqdm(glob.glob(f\"{BASE_DIR}/**/*.pdf\", recursive=True)):\n",
        "        text = extract_pdf_text(filepath)\n",
        "        if text:\n",
        "            topic = os.path.basename(filepath).replace(\".pdf\", \"\")\n",
        "            text_with_topics.append((topic, text))\n",
        "\n",
        "    for filepath in tqdm(glob.glob(f\"{BASE_DIR}/**/*.pptx\", recursive=True)):\n",
        "        text = extract_pptx_text(filepath)\n",
        "        if text:\n",
        "            topic = os.path.basename(filepath).replace(\".pptx\", \"\")\n",
        "            text_with_topics.append((topic, text))\n",
        "\n",
        "    return text_with_topics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "5sTf5QT6cYC6"
      },
      "outputs": [],
      "source": [
        "# Function to get answers from OpenAI API\n",
        "def get_answer_from_openai(prompt):\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",  # Update to a suitable chat model\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},  # System message for context\n",
        "            {\"role\": \"user\", \"content\": prompt}  # User message with the actual prompt\n",
        "        ],\n",
        "        max_tokens=150\n",
        "    )\n",
        "    return response.choices[0].message['content'].strip()  # Access the answer from the message content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Ftqmpwqshov9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# Function to save question and answer to a file\n",
        "def save_qa_to_file(topic, question, answer):\n",
        "    # Define the file path where questions and answers will be saved\n",
        "    qa_file_path = f\"{TEXT_DIR}/{topic}_qa.txt\"\n",
        "\n",
        "    # Create the directory if it doesn't exist\n",
        "    os.makedirs(os.path.dirname(qa_file_path), exist_ok=True)\n",
        "\n",
        "    # Open the file in append mode, so that new QAs are added without overwriting\n",
        "    with open(qa_file_path, \"a\", encoding=\"utf-8\") as f:\n",
        "        f.write(f\"Question: {question}\\n\")\n",
        "        f.write(f\"Answer: {answer}\\n\")\n",
        "        f.write(\"-\" * 80 + \"\\n\")  # Divider for readability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AkbHg6iQrEMH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlMaEPPdDRnO",
        "outputId": "f5ccb214-b5c1-40bd-8441-d71db4f85b23"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "0it [00:00, ?it/s]\n",
            "100%|██████████| 12/12 [00:00<00:00, 16.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Available topics:\n",
            "1. Intro to DevOps and Beyond\n",
            "2. Introduction to Microservices\n",
            "3. Containers 101\n",
            "4. CAP Theorem\n",
            "5. Cloud Design Patterns - 1\n",
            "6. AWS User Groups Colombo - Introduction to AWS Cloud Platform\n",
            "7. Microservice Design Patterns\n",
            "8. Lecture 2 - Part 1\n",
            "9. Key Essentials for Building Application in Cloud\n",
            "10. Cloud Computing 101\n",
            "11. Cloud Design Patterns - 2\n",
            "12. Lecture 2 - Part 2\n",
            "Select a topic by number: 5\n",
            "Ask a question related to the topic 'Cloud Design Patterns - 1': tell me the types of Cloud Design Patterns\n",
            "Generated Answer: Based on the provided context, the types of Cloud Design Patterns mentioned are as follows:\n",
            "\n",
            "1. Cache-Aside Pattern\n",
            "   - Solutions: Azure Cache, AWS ElastiCache, Google App Engine memcache, Redis Cache\n",
            "   - Pros: Increased performance\n",
            "   - Cons: Maintaining consistency between data in cache & data in the underlying data store\n",
            "   - Parameters: What to cache, Lifetime of cached data, Cache size, Evicting data, In-Memory Caching for read/write performance\n",
            "\n",
            "2. Competing Consumers Pattern\n",
            "   - Goals: Optimize throughput, improve scalability & availability, load balancing\n",
            "   - When: Independent tasks that can be processed in parallel, Volume of work is highly variable, High availability\n",
            "   -\n"
          ]
        }
      ],
      "source": [
        "# Function to handle user interaction, select topic, and generate Q&A\n",
        "def interact_and_generate_qa(text_with_topics):\n",
        "    print(\"Available topics:\")\n",
        "    topics = list(set([topic for topic, _ in text_with_topics]))  # Extract unique topics\n",
        "    for idx, topic in enumerate(topics, 1):\n",
        "        print(f\"{idx}. {topic}\")  # Print each topic\n",
        "\n",
        "    # Ask user to select a topic\n",
        "    try:\n",
        "        selected_topic_idx = int(input(\"Select a topic by number: \")) - 1\n",
        "        selected_topic = topics[selected_topic_idx]  # Retrieve selected topic\n",
        "    except (ValueError, IndexError):\n",
        "        print(\"Invalid selection. Please try again.\")\n",
        "        return\n",
        "\n",
        "    # Get chunks related to the selected topic\n",
        "    selected_chunks = [text for topic, text in text_with_topics if topic == selected_topic]\n",
        "\n",
        "    # Ask user for a question\n",
        "    question = input(f\"Ask a question related to the topic '{selected_topic}': \")\n",
        "\n",
        "    # Combine context (selected chunks) and question to form the prompt\n",
        "    context = \"\\n\".join(selected_chunks)[:3000]  # Limit context size to avoid token limits\n",
        "    # print(f\"\\nContext being sent to OpenAI API for the question:\")\n",
        "    # print(context)\n",
        "\n",
        "    prompt = f\"Answer the following question based on the context:\\n\\nContext: {context}\\n\\nQuestion: {question}\"\n",
        "\n",
        "    # Get the answer from OpenAI API\n",
        "    answer = get_answer_from_openai(prompt)\n",
        "\n",
        "    # Display the generated answer\n",
        "    print(f\"Generated Answer: {answer}\")\n",
        "\n",
        "    # Save the question and answer to a file\n",
        "    save_qa_to_file(selected_topic, question, answer)\n",
        "\n",
        "\"\"\"### Start the Extraction and Q&A Generation Process\"\"\"\n",
        "\n",
        "# Extract and chunk the text from the slides\n",
        "text_with_topics = extract_and_chunk_text()\n",
        "\n",
        "# Start the interactive session\n",
        "interact_and_generate_qa(text_with_topics)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
